% !TEX root = ../thesis.tex
%
\chapter{Applying optimal control theory to complex models\label{ch:complex_models}}

\section{Introduction\label{sec:ch4:Intro}}

In the previous chapters we have introduced OCT and shown how it can be used to find the best disease management strategies. The mathematical complexity of finding these optimal strategies however, means major simplifications to the system as modelled are required to allow progress to be made using OCT\@. There is no standard for putting the results from these mathematically motivated simplifications into practice, nor for assessing the impact of the model simplifications on predictive accuracy. As a result, it is often unclear how these strategies would perform if adopted by policy makers. In this chapter we will investigate frameworks for translating OCT results into practical and realistic management policies\footnote{This chapter is based on work published in \citet{bussell_applying_2019}. All code is available at \url{https://github.com/ehbussell/Bussell2018Model}}.

Robust policy decisions require accurate predictions of future disease dynamics. Increasingly, complex simulation models incorporating detailed representations of disease transmission processes are used to assess the potential impact of a given intervention strategy \citep{lofgren_opinion_2014}. To ensure accurate epidemic predictions, simulation models designed to aid decision making must often capture highly complex dynamics \citep[Chapter 1,][]{savary_simulation_2014}. As we discussed in Chapter 1, this often makes optimisation of control strategies infeasible, particularly when control measures can vary over time, in space or according to disease risk \citep{bellman_dynamic_1957}. For most simulation models the only viable option is then to evaluate a small subset of `user-defined' plausible strategies that remain fixed during the epidemic, potentially scanning over a single parameter such as a culling radius. We shall refer to this approach as `Strategy Testing'. Using this approach makes it difficult to have high confidence in the best-performing strategy, since with no framework for choosing it, the set of strategies under test is likely to be biased. Further to this, as the set of strategies to test will be very unlikely to span the entire space of control options, it is unlikely that the true optimum will be found.

In this chapter we ask whether and how the optimisation capabilities of OCT might be combined with the accurate predictions made by simulation models, to give improved management strategies. What framework should be applied to make practical use of OCT? This chapter will set the foundations for the methodology to be applied to real-world systems in the following chapters. In Section~\ref{sec:ch4:Frameworks} we describe two methods from control systems engineering for applying OCT results to simulation models: open-loop and model predictive control. A network epidemic model is developed in Section~\ref{sec:ch4:Controlling} to showcase these frameworks, and we illustrate the potential benefit of using OCT alongside simulation models in Section~\ref{sec:ch4:Results}. We seek to answer how, under current computational constraints, results from OCT can be applied whilst maintaining the realism required for practical application.

\section{Frameworks for practical optimal control\label{sec:ch4:Frameworks}}

In Chapter~\ref{ch:oct} we reviewed the history and use of OCT in epidemiology. Beyond epidemiology though, OCT has had much wider applications, particularly in engineering and economics \citep{bertsekas_dynamic_2001}. In mathematical biology, OCT has more recently been used to control complex, agent-based models (ABMs) \citep{an_optimization_2017}, a type of model that simulates the individual behaviour of autonomous agents. \citet{an_optimization_2017} suggest the use of a model that approximates the dynamics of the ABM, designed to be simple enough to allow mathematical analysis of the optimal control. A suitable approximate model is chosen and fitted either to real data, or to synthetic data from the ABM\@. The OCT results from the approximating model are then mapped onto the ABM to be tested: a process referred to as `lifting'. This process of applying OCT to an approximate model and lifting the results to a complex ABM could equally well apply to optimisation of detailed epidemic simulation models. We now describe two possible frameworks from control systems engineering based on this control lifting approach.

\subsection{Open-loop control}

The first method is the simplest application of control lifting, and the framework implicitly suggested by \citet{an_optimization_2017}. Control is optimised on the approximate model once using the initial conditions of the simulation model. The resulting optimal control strategy is lifted to the simulator and applied for the full simulation run time (Figure~\ref{fig:ch4:mpc_framework}). To account for stochasticity, repeated simulation of the OCT strategy using the simulator allows assessment against other possible control strategies. The optimisation gives a single, time dependent strategy for all simulation realisations, and so does not incorporate any feedback. It is therefore referred to as `open-loop' control, as it is fully specified by the simulation initial conditions and the trajectory predicted by the approximate model. Use in epidemiology is uncommon, although \citet{clarke_approximating_2013} use OCT in an approximate model to find optimal levels of Chlamydia screening and contact tracing which are then mapped onto a network simulation.

\begin{figure}
    \begin{center}
        \raisebox{-0.5\height}{\includegraphics[height=0.48\textwidth]{Graphics/Ch4/OL_MPC_Framework_a_label}}
        \hspace{0em}
        \raisebox{-0.5\height}{\includegraphics[height=0.48\textwidth]{Graphics/Ch4/MPC_Framework}}
        \hspace{0em}
        \raisebox{-0.5\height}{\includegraphics[height=0.48\textwidth]{Graphics/Ch4/OL_MPC_Framework}}

        \caption[Open-loop and model predictive control frameworks]{Open-loop and model predictive control (MPC) frameworks. In \textbf{(a)} the model hierarchy is shown, with optimised controls from the approximate model directly lifted to the simulation model. The real system is in green, the models and fitting processes are in blue, and the control framework is in orange. Without the orange dashed feedback loop, this is open-loop control. MPC resets the state of the approximate model at regular update steps, before re-optimising and lifting controls to the simulation model until the next update time. \textbf{(b)} shows how this works for open-loop control. The simulation model and approximate model match at the initial time, and control is based on the predicted spread. The predicted spread deviates from the simulation over time. In MPC, as shown in \textbf{(c)}, at regular update times the approximate model is reset to match the simulation, ensuring the deviation remains small.
        \label{fig:ch4:mpc_framework}}
    \end{center}
\end{figure}

\subsection{Model predictive control}

Open-loop control requires the approximate model to remain accurate over the time scale of the entire epidemic. For tractability, however, the approximate model must necessarily omit many heterogeneities present in the simulation model, such as spatial effects and risk structure. When strategies resulting from OCT are then applied to the simulation model or to the real system, the disease progress curve is likely to deviate systematically from the trajectory predicted by the approximate model. Model predictive control (MPC) is an optimisation technique incorporating system feedback that can take such perturbations into account \citep{camacho_model_1995, lee_model_2011}.

With MPC, both the approximate and simulation models are run concurrently. Optimal strategies are still lifted from the approximate model to the simulation, but at regular update times the values of the state variables in the approximate model are reset to match those in the simulation. The control is then re-optimised using the new initial conditions in the approximate model, and the new control strategy is applied to the simulation until the next update time. The approximate and simulation models are therefore run concurrently, with multiple time-limited optimisations per realisation, to ensure that the approximate model and control strategy closely match each individual simulation realisation (Figure~\ref{fig:ch4:mpc_framework}). These multiple optimisations are computationally costly but tractable, unlike performing optimisation on the full simulation model.

MPC has had some use within the epidemiological literature, the majority being for control of drug applications for single individuals rather than control of epidemics at the population level. Examples include finding management strategies for HIV that are robust to measurement noise and modelling errors \citep{zurakowski_model_2006, david_receding_2011}, and control of insulin delivery in patients with diabetes \citep{hovorka_nonlinear_2004}. These studies highlight the benefits of MPC for robust control, i.e.\ control that remains effective despite system perturbations. However, only one study concentrates on epidemic management \citep{selley_dynamic_2015}. In that study, \citeauthor{selley_dynamic_2015} develop a pairwise ODE model as an approximation of an epidemic on a network. Time-dependent control is optimised on this model, and applied using an MPC framework. Crucially though, the control is applied to the approximate model rather than to an individual based network simulation. This means the practical results of the strategy are not tested. In the bioinvasion literature, \citet{de_model_2019} apply MPC to the control of invasive golden mussels in rivers in Brazil, but again the control is not applied to a more complex model to test how the strategy would perform in practice.

\section{Controlling an epidemic spreading on a network\label{sec:ch4:Controlling}}

As an illustrative example which demonstrates open-loop and MPC for epidemic management, we use a stochastic SIR network model including host demography and risk structure, and vaccination as a control method. The model is deliberately kept simple to show how the underpinning idea is broadly applicable across plant, animal and human diseases. Whilst the model and its parameters are arbitrary and do not represent a specific disease, we use it to represent a scenario in which a simulation model has already been fitted to a real disease system; the network model is therefore used here as a proxy for a potentially very detailed simulation model. The model itself includes features abstracted from metapopulation or network epidemic models as routinely used for plant, animal and human diseases \citep{rowthorn_optimal_2009, keeling_dynamics_2001, keeling_metapopulation_2000, margosian_connectivity_2009, bansal_individual_2007}.

Both the open-loop and MPC frameworks require an approximate model with which optimisation using OCT is possible. The size of the system has a significant impact on the tractability of solving the optimal control problem, but complex dynamics can also make finding numerical solutions difficult, and there is no clear way to know a priori whether a solution will be possible. In this chapter we will use two different levels of approximation to assess how this approximate model should be chosen. The resulting strategies using both open-loop and MPC will be compared with a Strategy Testing approach, where a limited number of plausible interventions that do not vary during the epidemic are tested on the simulation model. 

\subsection{Simulation model}

In the simulation model, infection spreads stochastically across a network of nodes. Nodes are positioned randomly in three separate regions, with 20 nodes in regions A and C, and 15 nodes in region B (Figure~\ref{fig:ch4:node_structure_and_model}(a)). The nodes are positioned such that no two nodes are closer than a predetermined threshold, here 0.2 spatial units. This threshold avoids very high connectivity between any nodes. The connectivity between nodes within a region is calculated using an exponential kernel with a scale parameter $\alpha$ of 0.2 units ($\sigma_{ij} = \mathrm{e}^{-d_{ij}/\alpha}$) where $d_{ij}$ is the distance between nodes $i$ and $j$. Between regions, three connections are made between the closest pairs of nodes in regions A and B, and B and C, with a coupling value of $0.1\beta$ for each. This is approximately equal to the average coupling between pairs of nodes within the two larger regions, A and B. There are no connections between regions A and C. Note that this network is arbitrary, and is used simply as an illustrative scenario.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.5\textwidth]{Graphics/Ch4/Node_Structure}
    \includegraphics[width=0.5\textwidth]{Graphics/Ch4/Model_Structure}
    \caption{\textbf{(a)} The network used for the simulation model, including region labels. The epidemic is seeded in the red node in region A, and can spread between connected nodes (grey lines). \textbf{(b)} Diagram of host states and transitions. For transition rates see Table~\ref{tab:ch4:rates}. Hosts are classed as susceptible ($S$), infected ($I$), vaccinated ($V$), or removed ($R$).}
    \label{fig:ch4:node_structure_and_model}
\end{figure}

Each node initially contains a total of 30 hosts, stratified into high and low risk groups with different infection rates. High risk nodes are both more susceptible to the disease, as well as more infectious once infected. On average 10\% of hosts within each node start in the high risk group. To give heterogeneity across the network the exact number of high risk hosts for each node is chosen using a binomial trial. Each individual host can be in one of three active states: susceptible ($S$), infected ($I$) or vaccinated ($V$), or removed ($R$) by the disease (Figure~\ref{fig:ch4:node_structure_and_model}(b)). The infection can spread between individuals within nodes and between connected nodes. The net rate of infection of risk group $r$ in node $i$ is given by:
\begin{equation}\label{eqn:ch4:sim_model}
    S_i^r \sum_j\beta\sigma_{ij} \left(\rho^{rH}I_j^H + \rho^{rL}I_j^L\right)\;,
\end{equation}
where $S$ and $I$ are numbers of susceptible and infected hosts respectively. Throughout superscripts refer to the risk group (high: H, low: L), and subscripts identify the node. For example, $S_{3}^\mathrm{H}$ represents the total number of high risk susceptibles in node 3. In addition, we use $N$ to refer to the total number of active hosts that could be controlled, such that $N_{3}^\mathrm{H}$ is the number of susceptible, infected and vaccinated high risk hosts in node 3. The sum in Equation~\ref{eqn:ch4:sim_model} is over all connected nodes including the focal node itself, with the relative transmission rate into node $i$ from node $j$ given by $\sigma_{ij}$, and risk structure given by the \num{2x2} matrix $\rho$.

Mass vaccination is the only intervention we consider, with the potential to target based on both risk group and region but randomised across host infection status (i.e.\ the vaccine is given to all hosts but is only effective on susceptibles). Vaccinated hosts are not susceptible to infection, i.e.\ the vaccine is totally effective, and the vaccine does not wane over the time scales considered here. Logistical and economic constraints are included through a maximum total vaccination rate ($\eta_{\mathrm{max}}$) that can be divided between risk groups and regions. Within each group susceptibles are vaccinated at rate $f\eta_{\mathrm{max}}S/N$, where $f$ is the proportion of control allocated to that group, and $N$ is the total group population.

Trajectories are simulated using the Gillespie direct method \citep{gillespie_exact_1977}. The possible events are host birth and death, infection, vaccination, and removal and recovery of infected hosts (Figure~\ref{fig:ch4:node_structure_and_model}(b)). These events and the associated rates are given in Table~\ref{tab:ch4:rates}. Parameters, as specified in Table~\ref{tab:ch4:parameters}, were chosen to give a large epidemic under no control intervention, spreading across all three regions. Typical simulation trajectories with no control are shown in Figure~\ref{fig:ch4:no_control_dpc}.

\begin{figure}[htb]
    \begin{center}
        \includegraphics[width=\textwidth]{Graphics/Ch4/No_Control_DPC}
        \caption{Ten typical simulation model trajectories with no control. Green and red lines represent susceptible and infected hosts respectively.\label{fig:ch4:no_control_dpc}}
    \end{center}
\end{figure}

Optimal allocation of vaccination resources minimises an epidemic cost $J$ representing the disease burden of the epidemic across all infected hosts over the simulation time ($T$):
\begin{equation}
    J = \int_{t=0}^TI(t)\mathrm{d}t\;,
\end{equation}
where $I$ is the total number of infected hosts across the network. In common with the particular control we consider and the risk and spatial structures, this simple choice of objective function was made merely to illustrate our methods, but as we later show in Chapters~\ref{ch:protect_tanoak_control} and \ref{ch:redwood}, the framework generalises immediately to more complex settings.

\begin{table}
    \centering
    \caption{Possible events in the simulation model with associated rates.\label{tab:ch4:rates}}
    \begin{tabular}{@{}lll@{}}
        \toprule
        \textbf{Event} & \textbf{State Change} & \textbf{Rate} \\
        \midrule
        Birth & $\emptyset \rightarrow S_i^r$ & $bN_i^r$\\
        Death & $\{S_i^r,I_i^r,V_i^r\} \rightarrow \emptyset$ & $dN_i^r$ \\
        Infection & $S_i^r \rightarrow I_i^r$ & $S_i^r\sum_{j,r'}\sigma_{ij}\rho^{rr'}I_j^{r'}$\\
        Vaccination & $S_i^r \rightarrow V_i^r$ & $f_i^r\eta_{\textrm{max}}S_i^r / N_i^r$\\
        Removal & $I_i^r \rightarrow \emptyset$ & $\mu{}I_i^r$\\
        Recovery & $I_i^r \rightarrow S_i^r$ & $\nu{}I_i^r$\\
        \bottomrule
    \end{tabular}
\end{table}
        
\begin{table}[htb]
    \centering
    \caption{Parameter values used for simulation model trajectories. Note that the units of time are arbitrary.\label{tab:ch4:parameters}}
    \begin{tabular}{@{}lll@{}}
        \toprule
        \textbf{Meaning} & \textbf{Parameter} & \textbf{Default Value} \\
        \midrule
        Birth Rate & $b$ & \SI{0.01}{\per\t}\\
        Death Rate & $d$ & \SI{0.01}{\per\t}\\
        Maximum Vaccination Rate & $\eta{}_\textrm{max}$ & \SI{200}{\hosts\per\t}\\
        Removal Rate & $\mu$ & \SI{0.5}{\per\t}\\
        Recovery Rate & $\nu$ & \SI{0.25}{\per\t}\\
        Risk Coupling & $\left(\begin{smallmatrix}
            \rho^{\mathrm{HH}}& \rho^{\mathrm{HL}}\\
            \rho^{\mathrm{LH}}& \rho^{\mathrm{LL}}
            \end{smallmatrix}\right)$ & $\left(\begin{smallmatrix}
            \num{1.0}& \num{0.008}\\
            \num{0.008}& \num{0.016}
        \end{smallmatrix}\right)$\\
        Spatial Coupling & $\sigma$ & \textit{see text}\\
        Transmission Rate & $\beta$ & \SI{2.5}{\per\host\per\t}\\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Approximate models}

Exhaustive optimisation of control using the simulation model, across space, risk group and time, would clearly be impossibly computationally expensive. To make optimisation feasible we use an approximate model, as described in Section~\ref{sec:ch4:Frameworks}. To assess the best level of approximation, we consider two different deterministic approximate models of the simulator. The first model is purely risk structured, factoring out all spatial information and leaving one high risk and one low risk population group. This model is therefore based on the assumption that all nodes are spatially well-mixed with each other, and so we refer to it as the risk based model.

The second approximate model is more complex, in as much as it is also deterministic and risk structured, but also groups hosts by region. The model is therefore split into three regions, with two risk classes but no spatial structure within each region. Spatial dynamics are included between but not within the three regions to maintain enough simplicity to obtain optimal control results, thereby assuming that nodes are spatially well-mixed within each region. This could represent, for example, optimising control at the country level, but not at the regional level. We refer to this model as the spatial approximate model.

\subsubsection*{Risk based approximate model}

This model factors out all spatial information from the simulations, and approximates the resulting risk structure using a set of ordinary differential equations. The ODE system has one equation for each of the six host states: susceptible, infected and vaccinated in the high risk ($S^\mathrm{H}, I^\mathrm{H}, V^\mathrm{H}$), and low risk groups ($S^\mathrm{L}, I^\mathrm{L}, V^\mathrm{L}$). The state values are mapped from the simulations simply by summing all hosts in that state across the whole network (e.g.\ $S^r = \sum_{i}S^r_i$). For risk group $r$, the full system of equations is given by:
\begin{subequations}\label{eqn:ch4:risk_model}
\begin{alignat}{7}
    \dot{S}^r &={} &bN^r &{}-{} dS^r &{}-{} S^r\left(\hat{\rho}^{r\mathrm{H}}I^{\mathrm{H}} + \hat{\rho}^{r\mathrm{L}}I^{\mathrm{L}}\right) &{}-{} \frac{f^r\eta{}_\mathrm{max}S^r}{N^r} &&{}+{} \nu{}I^r \\
    \dot{I}^r &={}  &&{}-{} dI^r &{}+{} S^r\left(\hat{\rho}^{r\mathrm{H}}I^{\mathrm{H}} + \hat{\rho}^{r\mathrm{L}}I^{\mathrm{L}}\right)& &{}-{} \mu{}I^r &{}-{} \nu{}I^r \\
    \dot{V}^r &={}  &&{}-{} dV^r &&{}+{} \frac{f^r\eta{}_\mathrm{max}S^r}{N^r}&&
\end{alignat}
\end{subequations}
where $\hat{\rho}$ is a \num{2x2} matrix giving the approximated risk structure, i.e.\ the rate at which each risk group infects each other risk group. This must be calculated by a model fitting step (see \S\ref{sec:ch4:model_fitting}), since the exact spatial structure is not modelled. All other parameters are specific to individual hosts and so can be lifted from the simulation model.

\subsubsection*{Spatial approximate model}

This model includes regional spatial information as well as risk structure. This gives 18 possible states: susceptible, infected and vaccinated across risk groups (high and low), and regions ($A$, $B$ and $C$). The states here are summed across nodes within a region (e.g.\ $S^r_A = \sum_{i\in{}A}S^r_i$). For risk group $r\in{}\{\mathrm{H,L}\}$, and region $X\in{}\{A,B,C\}$, the system of differential equations is given by:
\begin{subequations}
    \begin{alignat}{7}
        \dot{S}^r_X &={} &bN^r_X &{}-{} dS^r_X &{}-{} S^r_X\sum_{\substack{X'\in\\\{A,B,C\}}}\tilde{\sigma}_{XX'}\left(\tilde{\rho}^{r\mathrm{H}}I^{\mathrm{H}}_{X'} + \tilde{\rho}^{r\mathrm{L}}I^{\mathrm{L}}_{X'}\right) &{}-{} \frac{f^r_X\eta{}_\mathrm{max}S^r_X}{N^r_X} &&{}+{} \nu{}I^r_X \\
        \dot{I}^r_X &={}  &&{}-{} dI^r_X &{}+{} S^r_X\sum_{\substack{X'\in\\\{A,B,C\}}}\tilde{\sigma}_{XX'}\left(\tilde{\rho}^{r\mathrm{H}}I^{\mathrm{H}}_{X'} + \tilde{\rho}^{r\mathrm{L}}I^{\mathrm{L}}_{X'}\right)& &{}-{} \mu{}I^r_X &{}-{} \nu{}I^r_X \\
        \dot{V}^r_X &={}  &&{}-{} dV^r_X &&{}+{} \frac{f^r_X\eta{}_\mathrm{max}S^r_X}{N^r_X}\;.
    \end{alignat}
    \label{eq:space_model}
\end{subequations}
The \num{3x3} matrix $\tilde{\sigma}$ approximates spatial coupling between regions, and $\tilde{\rho}$ is again a \num{2x2} matrix giving the approximated risk structure (but note that the parameters will be different from the risk based model).

\subsection{Model fitting\label{sec:ch4:model_fitting}}

The approximate models both have parameters that must be fitted to the simulation model output. This ensures the dynamics of the simulation are captured as accurately as possible given the simplifications made in the approximate models. For both models we use maximum likelihood estimation (MLE) to fit the parameters \citep{aldrich_ra_1997}. States must be mapped between the simulation model and the approximate models. As stated before, the simulation states are simply summed across all nodes in the network for each risk group in the risk based model, and by region for the spatial approximate model.

To fit the risk based model the 4 parameters in $\hat{\rho}$ must be chosen. The likelihood is the probability of observing a set of simulation realisations, given a parameter set in the approximate model. This likelihood is maximised to find the best fitting set of parameters. The likelihood is computed as the product of contributions from 200 realisations of the simulation model with no interventions (i.e.\ no control is implemented). Since all events occur with exponentially distributed waiting times, each individual event within a realisation occurring after a time $\delta{}t$ contributes a factor $\delta{}L_i$ to the likelihood:
\begin{equation}
\delta{}L_i = r_k\mathrm{e}^{-\sum{}r_i\delta{}t}\;.
\end{equation}
The $r_i$ are the rates of all possible events, and $r_k$ is the rate of the event that actually occurs. This $\delta{}L_i$ is the probability of observing that event, given the rates of all events, which are calculated from Equations~\ref{eqn:ch4:risk_model}. The full likelihood is the product of all $\delta{}L_i$ across all realisations. This overall likelihood is then maximised by varying  $\hat{\rho}$.

The same fitting procedure is used to fit $\tilde{\rho}$ and $\tilde{\sigma}$ in the space based model. Here there are a total of 13 parameters, but we set $\tilde{\rho}^\mathrm{HH}$ to one to ensure identifiability (since the infection rate is proportional to the product of $\tilde{\rho}$ and $\tilde{\sigma}$). We also set the coupling between regions $A$ and $C$ ($\tilde{\sigma}_{AC}$ and $\tilde{\sigma}_{CA}$) to zero, as well as from $B$ into $A$ and from $C$ into $B$. This is because the epidemic spreads from $A$ to $B$ to $C$, and backward spread is negligible. This leaves a total of 8 parameters to fit.

Fits to simulation data are shown for the risk based model in Figure~\ref{fig:risk_fit}, and in Figure~\ref{fig:space_fit} for the space based model. The risk model captures the median risk dynamics well. The highly stochastic nature of spread between regions however, means the spatial model does not capture the timings of introductions accurately. This effect is due to stochastic fade outs after introduction events, as well as negative covariance between susceptible and infected hosts, leading to reduced infection rates in the stochastic simulations \citep[pp.~227--229 and pp.~238--240]{keeling_modeling_2008}. For now we continue to use MLE despite this limitation, \todo{but we show in Appendix~\ref{app:mle_sse} that alternative fitting methods do not change our results (is this necessary?)}.

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.75\textwidth]{Graphics/Ch4/Risk_Fit}
        \caption{Fits to simulation data for the risk based model. Dashed lines show the risk model, and faded lines show 20 of the simulation runs. Green and red lines represent susceptible and infected hosts respectively.}
        \label{fig:risk_fit}
    \end{center}
\end{figure}

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=\textwidth]{Graphics/Ch4/Space_Fit}
        \caption{Fits to simulation data for the space based model. Dashed lines show the space model, and faded lines show 20 of the simulation runs. Green and red lines represent susceptible and infected hosts respectively. We note that the approximate dynamics are faster than those in the simulations. This effect is explained in the text.\label{fig:space_fit}}
    \end{center}
\end{figure}

To verify the optimisation we generated profile likelihood plots \citep{bolker_ecological_2008}, shown in Figure~\ref{fig:profile_lik}. Each parameter is fixed at one value, and all other parameters are then fitted to maximise the likelihood. This shows the maximum possible likelihood for each parameter value, and verifies that the fitting process has found the correct maximum. A confidence interval can be constructed from the log-likelihood ratio statistic, finding the likelihood at which there is a \SI{95}{\percent} probability of difference between the models. This corresponds to:
\begin{equation}
    2\log\left\{\frac{\hat{\pi}}{\pi}\right\} \leq \chi^2_{95}(1)
\end{equation}
where $\hat{\pi}$ is the maximum likelihood, and $\pi$ is the profile likelihood, and these are compared with the 95\textsuperscript{th} percentile of the chi-squared distribution with one degree of freedom. All profile likelihoods cross this threshold, meaning that the parameters are identifiable.

\begin{figure}
    \begin{center}
        \includegraphics[width=\textwidth]{Graphics/Ch4/Profile_Likelihoods}
        \caption{Profile likelihood analysis for: \textbf{(a)} the risk based approximate model, and \textbf{(b)} the space based approximate model. The offsets ($1.137\times10^6$ for \textbf{(a)} and $9.583\times10^5$ for \textbf{(b)}) must be added to all values on the y axes. The profile for every parameter crosses the 95\% confidence interval threshold, ensuring identifiability of each parameter. In all cases maximum likelihood estimates from the unconstrained optimisation coincide with the maximum along the profile.}
        \label{fig:profile_lik}
    \end{center}
\end{figure}

\FloatBarrier
\subsection{Control scenario testing}

We test six different control scenarios, which compare Strategy Testing of controls based purely on the simulation model (scenarios 1 and 2, `user-defined') with open-loop and MPC applied using both of our approximate models (scenarios 3 to 6):
\begin{enumerate}
    \setlength{\itemsep}{3pt}%
    \setlength{\parskip}{3pt}%
    \setlength{\parsep}{3pt}%
    \item{}`High': exclusively vaccinate high risk individuals
    \item{}`Split': partition control resources between high and low risk groups based on an optimisation performed in advance using the simulation model only
    \item{}`Risk OL': open-loop control using the risk based approximate model
    \item{}`Risk MPC': MPC using the risk based approximate model
    \item{}`Space OL': open-loop control using the spatial approximate model
    \item{}`Space MPC': MPC using the spatial approximate model
\end{enumerate}

The optimal constant allocation for the `Split' strategy was found by running many simulation model realisations for each of a range of partition values, as in \citet{cunniffe_optimising_2015}, and selecting the value that gave the lowest average epidemic cost. The six strategies are assessed by repeatedly running the simulation model under each control scenario.

Optimisation in scenarios 3 to 6 is carried out using BOCOP v2.0.5 \citep{bocop}, as in Chapter 3. We implement open-loop and MPC using Algorithm~\ref{alg:ch4:ol_mpc}. When lifting the resulting controls to the simulation model, resources are allocated such that all active individuals within the targeted group have an equal probability of being vaccinated. With the risk based model, resources are allocated across all nodes and active individuals in the targeted risk group are selected randomly. Note again though that the vaccine is only effective on susceptible hosts. In the space based model resources are spread over nodes in the targeted region. Again, the probability of selecting any single active host is constant. This amounts to weighting the resource allocated to a particular node by its total population.
 
\begin{algorithm}
    \begin{enumerate}
        \item{}Fit simulation model to real data
        \item{}Set initial conditions for simulation model
        \item{}Fit approximate model to simulation data
        \item{}Initialise approximate model at current simulator state
        \item{}Optimise control on approximate model
        \item{}Lift control to simulation model and simulate forward
        \item{}If MPC then at next update time go to step 4
    \end{enumerate}
\caption{MPC and open-loop algorithms. Open-loop simulates for the full time (i.e.\ step 2--6), whereas MPC re-optimises the control at the update times (step 2--7 with repeated loops back to step 4).\label{alg:ch4:ol_mpc}}
\end{algorithm}

To fully compare open-loop and MPC we must run the simulations repeatedly to account for stochasticity. We do this using both approximate models as well as with the naive `High' and `Split' strategies that do not use optimal control theory. As described before the `High' strategy allocates all control resources to the high risk group. The `Split' strategy uses an optimisation performed in advance using the simulation model. By running the simulation model repeatedly, allocating different resource proportions to the high and low risk groups, the optimal constant ratio can be found by minimising the mean objective value (Figure~\ref{fig:ch4:risk_split_scan}). The proportion that gives the lowest mean objective value is found to be 63\% to the high risk group, with the rest used to vaccinate low risk individuals. As shown in Figure~\ref{fig:ch4:risk_split_scan} the optimum occurs in a very broad minimum, so the precise value of the optimal split is uncertain. Since the precise value has little effect on the epidemic cost (hence the broad minimum), we simply use 63\% as a representative value.

\begin{figure}[t!]
    \begin{center}
        \includegraphics[width=0.75\textwidth]{Graphics/Ch4/Risk_Split_Scan}
        \caption{Scan of objective values for 1000 simulations, varying the proportion of control that is allocated to the high risk group. Remaining control is allocated to the low risk group. The optimal allocation to the high risk group is found to be 63\%. Deciles in the objectives are shown by the gradient in colour.}
        \label{fig:ch4:risk_split_scan}
    \end{center}
\end{figure}

\FloatBarrier
\newpage
\section{Results\label{sec:ch4:Results}}

\subsection{OCT strategies}

We first look at the OCT results from optimisation on the two approximate models. The optimal vaccination strategy in the risk based approximate model vaccinates high risk hosts exclusively early in the epidemic (Figure~\ref{fig:ch4:opt_control_comparison}(a)). The strategy then switches to vaccinating both high and low risk hosts, with the majority of control resources allocated to the low risk group. There is then a further switch to vaccinating the low risk group exclusively. The optimal strategy in the space based model shows a very similar allocation to risk groups across time (figure~\ref{fig:ch4:opt_control_comparison}(b)), but shifts these allocations across regions as the epidemic spreads through the network (figure~\ref{fig:ch4:opt_control_comparison}(c)). This allows the control to track the progress of the epidemic, and hence target control more effectively. The spatial strategies are therefore much more complex than the risk based controls.

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.75\textwidth]{Graphics/Ch4/OL_Control_Comparison}
        \caption{Comparison of optimal control strategies in the approximate models. \textbf{(a)} shows the optimal allocation of control resources to high and low risk groups in the risk based approximate model. \textbf{(b)} shows the equivalent for the space based approximate model. This allocation is broken down further in \textbf{(c)}, showing the distribution across regions and risk groups for the space based model.}
        \label{fig:ch4:opt_control_comparison}
    \end{center}
\end{figure}

\subsection{Strategy testing}

Next we compare the different control scenarios applied to the simulation model. This could give a more realistic indication of performance in the real world, since the simulation model is a more accurate representation of reality. First we compare the strategies resulting from the open-loop and MPC frameworks. The open-loop framework uses the same control strategy (as described in the previous section) for every realisation of the simulation model. Since the simulations are stochastic the epidemic will be different in each realisation, but the time-dependent control is the same each time. The MPC framework can update the control dependent on how the individual realisation has progressed. Each realisation will therefore have a different control strategy. Figure~\ref{fig:ch4:ol_mpc_comparison}(a) shows the control strategy for a single realisation using open-loop and MPC with the space based model. Figures~\ref{fig:ch4:ol_mpc_comparison}(b) and (c) show the corresponding disease progress curves in the simulation alongside the predictions made by the approximate model. We can see that the MPC framework changes the control allocations to account for deviations from the predicted behaviour. By resetting and re-optimising the approximate model the control strategy is tailored to the individual realisation. This allows the MPC framework to keep the number of infected hosts significantly lower than with the open-loop framework (note the different y axis scales on Figure~\ref{fig:ch4:ol_mpc_comparison}(b) and (c)).

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=\textwidth]{Graphics/Ch4/OL_MPC_Comparison}
        \caption{In \textbf{(a)} the control allocation is shown for a single space based MPC run, with the corresponding open-loop allocation indicated by the black dotted line. \textbf{(b)} shows the total number of infected individuals under a single run of space based open-loop control. Control is based on the prediction of the approximate model starting from the initial conditions. \textbf{(c)} shows the number of infected individuals in the simulation and space based approximate model corresponding to the MPC control carried out in \textbf{(a)}. Here the prediction is reset to match the simulation at every update step (0.5 time units) and the control is re-optimised. By repeatedly correcting for differences between short-term model predictions and realised numbers of infected individuals -- rather than relying on a potentially increasingly inaccurate prediction made at the initial time -- MPC gives better predictions of the simulation state as well as improved control when compared to open-loop (note different y axis scales).}
        \label{fig:ch4:ol_mpc_comparison}
    \end{center}
\end{figure}

For each control scenario we run the simulation model 250 times to generate a distribution of objective values (Figure~\ref{fig:ch4:obj_values}). We can see from these distributions that the `Split' strategy gives lower objective values, and hence improved control, compared to the `High' strategy. Using the risk based approximate model improves the epidemic management further, but with little difference between the open-loop and MPC frameworks. Adding space into the approximate model improves control further, leading to the smallest epidemic costs when the spatial MPC framework is used.

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.75\textwidth]{Graphics/Ch4/Obj_Values}
        \caption{Results of different control optimisation schemes on the illustrative simulation model. Spatial MPC performs best, showing an improvement over both open-loop and user-defined strategies.}
        \label{fig:ch4:obj_values}
    \end{center}
\end{figure}

The results here demonstrate the management improvements that can be achieved by combining OCT with both open-loop and MPC frameworks. The key results of the OCT analyses are the control switching times. Using the switching controls from either approximate model with open-loop control gives lower epidemic costs than the naively chosen `user-defined' strategies. The feedback present in the MPC controllers allows further reductions to the epidemic cost. By re-evaluating the timing of the switches during the epidemic, and potentially including additional switches, the control can respond more closely to the exact trajectory of the current simulation realisation (Figure~\ref{fig:ch4:ol_mpc_comparison}). This gives control that is more robust to uncertainty and systematic errors in the approximate model, and hence performs better on the complex simulation model.

In the risk based strategies there is little difference between open-loop and MPC\@. This is because the precise timing of the switch from high to low risk group vaccination does not significantly affect the epidemic cost (Figure~\ref{fig:ch4:switch_time_scan}). The timings of disease introduction into regions B and C are highly variable between simulation runs (Figure~\ref{fig:ch4:no_control_dpc}). The potential for additional switches in the spatial approximate model gives more flexibility for the MPC controller to respond to this variability, and so spatial MPC shows a significant improvement over open-loop which cannot adapt to perturbations. The performance of the control is closely linked to the accuracy of the approximate model. In our example, spatial dynamics are clearly important because of the timing of spread between regions, and so the more informed controls of the spatial model outperform the risk based strategies.

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.9\textwidth]{Graphics/Ch4/Switch_Time_Scan}
        \caption[Effect of switch time on strategy performance]{Scan over switch time showing distribution of objective values for 1000 simulations at each time. The switch time specifies when the control stops vaccinating only high risk hosts, and starts vaccinating only low risk hosts. Deciles in the objectives are shown by the gradient in colour. Whilst the switch time does affect performance, the precise timing does not vary the epidemic cost significantly.}
        \label{fig:ch4:switch_time_scan}
    \end{center}
\end{figure}

\FloatBarrier

\subsection{Parameter robustness\label{sec:ch4:Results_ParameterRobustness}}

The MPC framework is expected to provide improved control regardless of the exact form taken by the model or objective function. This does, however, rely on using an appropriately accurate approximate model so that the OCT results are based on realistic dynamics. We tested a range of arbitrary but reasonable parameter sets, and in all cases the spatial MPC framework performs best in this network model. To illustrate this in a concrete setting we explore systematic adjustments to the risk structure used in the simulation model.

The risk structure is defined by the matrix $\rho$ which in the standard simulation model is given by:
{\renewcommand{\arraystretch}{1}
\begin{equation}
    \begin{alignedat}{3}
        \rho &= \small{\begin{pmatrix}
            \rho^{\mathrm{HH}}& \rho^{\mathrm{HL}}\\
            \rho^{\mathrm{LH}}& \rho^{\mathrm{LL}}
            \end{pmatrix}} &= \small{\begin{pmatrix}
            \num{1.0}& \num{0.008}\\
            \num{0.008}& \num{0.016}
        \end{pmatrix}}
    \end{alignedat}
\end{equation}
}
We make the system more homogeneous or more heterogeneous by respectively doubling or halving $\rho^{\mathrm{HL}}$, $\rho^{\mathrm{LH}}$ and $\rho^{\mathrm{LL}}$. That is, the two alternative matrices used are:
{\renewcommand{\arraystretch}{1}
\begin{subequations}
    \begin{alignat}{2}
        \rho_{\mathrm{hom}} &= \small{\begin{pmatrix}
            \num{1.0}& \num{0.016}\\
            \num{0.016}& \num{0.032}
        \end{pmatrix}} \\
        \rho_{\mathrm{het}} &= \small{\begin{pmatrix}
            \num{1.0}& \num{0.004}\\
            \num{0.004}& \num{0.008}
        \end{pmatrix}}
    \end{alignat}
\end{subequations}
}
Using these values we then scale the transmission rate parameter, $\beta$, such that the mean epidemic cost under no control is within 1\% of that using the standard risk structure. The values were found to be 1.49 and 4.30 for the more homogeneous and heterogeneous cases respectively, compared with 2.5 for the default risk structure. The value of $\rho^{\mathrm{HH}}$ is left equal to one without loss of generality since the whole matrix is scaled by $\beta$. The means we only vary the relative transmission rates.

For each new $\rho$ matrix, we rerun the full analysis described above, assessing the same six control scenarios with refitted approximate models. Two main effects can be investigated using this analysis. Firstly, the ordering in performance of the six control scenarios can be compared with the ordering using the default risk structure, $\rho$. Secondly the performance of each strategy can be compared with the same strategy using $\rho$. We now look at each of these in turn.

For $\rho_{\mathrm{hom}}$, the more homogeneous case, we find that the order of the control scenarios is unchanged (Figure~\ref{fig:ch4:rho_homo}). As before we find that spatial MPC leads to the best performance, as found for the default $\rho$. The more heterogeneous case results in a different ordering of control strategy performance (Figure~\ref{fig:ch4:rho_hetero}). The ordering of the `user-defined' and risk based strategies is as before, but when using $\rho_{\mathrm{het}}$ the spatial open-loop scenario leads to worse performance than the risk based strategies. This is because for this parameter set, and approximate model, the resulting strategies cannot respond to the variability in regional introduction times, meaning that control is then targeted at the wrong regions. Importantly though, the spatial MPC strategy reduces average epidemic costs below those of all other strategies. Here the feedback strategy can greatly improve disease management, despite the limitations of the standard open-loop approach. This is similar to the effect seen by \citet{forster_optimizing_2007}, where inaccuracies in the switch times lead to ineffective control, but here the feedback loop has mitigated this issue, ensuring that the OCT results are still beneficial.

\begin{figure}
    \begin{center}
        \includegraphics[width=0.75\textwidth]{Graphics/Ch4/Rho_Homo}
        \caption{Results of control optimisation scenarios with alternative, more homogeneous risk structure $\rho_{\mathrm{hom}}$.}
        \label{fig:ch4:rho_homo}
    \end{center}
\end{figure}

\begin{figure}
    \begin{center}
        \includegraphics[width=0.75\textwidth]{Graphics/Ch4/Rho_Hetero}
        \caption{Results of control optimisation scenarios with alternative, more heterogeneous risk structure $\rho_{\mathrm{het}}$.}
        \label{fig:ch4:rho_hetero}
    \end{center}
\end{figure}

We now consider the second effect, namely relative performance of each strategy under the different risk structures (Figure~\ref{fig:ch4:rho_relative}). For $\rho_{\mathrm{hom}}$, the `user-defined' and risk based strategies have higher epidemic costs than were found with the default risk structure, $\rho$. This is because with a more homogeneous system, risk is less important and so the risk based strategies are less powerful. Using $\rho_{\mathrm{het}}$ the risk based strategies perform relatively better because of the increased importance of risk structure in the simulations. There is little change in epidemic cost for the spatial open-loop strategy using all three risk structures.

\begin{figure}
    \begin{center}
        \includegraphics[width=0.75\textwidth]{Graphics/Ch4/Rho_Relative}
        \caption{Mean performance of each control strategy using all three risk structures.}
        \label{fig:ch4:rho_relative}
    \end{center}
\end{figure}

\FloatBarrier

\section{Discussion}\label{sec:ch4:Discussion}

In this chapter we have described the open-loop and MPC frameworks for applying results from OCT to complex, simulation models. Using an illustrative network model we have demonstrated how both frameworks can find strategies that are an improvement over `user-defined' policies. The feedback loop in the MPC framework though, improves control further, by ensuring the simulation and approximate models are always closely aligned. In this section we will discuss some of the limitations and outstanding questions about the frameworks, and how the resulting controls might be applied in practice.

\subsection{Applying and testing OCT}

In this chapter we aimed to find methods for putting OCT results into practice. We focussed on how OCT can be used, when coupled with a simulation model using the open-loop or MPC frameworks, to optimise control in a complex system. The lifting of results to a simulation model that captures more realism allows the assumptions in the approximate model to be tested. This testing of OCT results is vital to ensure that the mathematical results are at all applicable in the real world.

Coupling OCT with simulation models allows strategy design to make the most out of both systems: OCT brings mathematical rigour and optimisation of time-dependent controls, whilst simulation models allow for highly accurate predictions of future spread. The simulation model we used here was a stochastic network model, but it can be any model that can accurately evaluate control strategies for the system in question. The example in this chapter showed that the OCT strategies from the approximate model performed well on the simulation, but in general it can be difficult to know when an OCT approach is likely to be effective, and whether to apply the open-loop or MPC framework. When the simulation model accurately captures real-world dynamics, the ultimate test to answer these questions is to compare them when applied to the simulation model, as we have done in this chapter.

\subsection{Robust framework}

As well as knowing whether open-loop or MPC will be more effective, choosing an appropriate approximate model can be challenging. Our results show that the choice of approximate model significantly affects the performance of both open-loop and MPC strategies. Here we have found a suitable approximate model in an ad hoc manner, by testing two potential models. Clearly other choices could have been made though, for example the three-patch model from Chapter~3 would also have been appropriate. Exhaustively testing all possible options is unlikely to be feasible though, so modelling decisions must be made to determine what approximations are likely to be valid and how much complexity is necessary.

A more accurate model may give better predictions, and hence control that is closer to the true optimum, but simpler models are often sufficient \citep{thompson_effect_2018}, and accuracy must be balanced with added complexity and optimisation constraints. It may not always be clear whether the complexity of a model will be prohibitive in solving the optimal control problem. The number of state and control variables is the main factor affecting tractability, but complex dynamics can also influence convergence. An advantage of the direct optimisation approach though, is that adjoint and Hamiltonian equations do not have to be derived for each model. This can speed up the testing of a plausible approximate model. As well as this, the open-loop and MPC frameworks can be applied to any simulation and approximate models. The only requirement is that there is a mapping of states and controls between the two models. 

The frameworks are also agnostic to the form of the objective function. The choice of objective function can significantly impact optimal control strategies \citep{probert_decision_2016}, and in this chapter we chose a very simple objective. The frameworks immediately extend to other choices of objective function though. An advantage of OCT is the ability to balance multiple costs, as shown, for example, by \citet{brown_role_2011} and \citet{bokil_optimal_2019}. In Chapter~\ref{ch:protect_tanoak_control} we show how objectives can be used that balance economic, cultural, and ecological management goals.

The feedback in the MPC framework ensures the approximate model and optimised control match the simulation realisation, making the system robust to differences between the models. Whilst exhaustive testing of alternative simulation model parameterisations is beyond the scope of this study, we have shown that the performance of MPC is robust to one type of re-parameterisation in Section~\ref{sec:ch4:Results_ParameterRobustness}. We have assumed throughout that an accurate simulation model of the real system in question can be built, and that a single set of parameters can be fitted for the chosen deterministic approximate model. In reality, in plant disease modelling parameters are often fitted to limited data using Bayesian methods, leading to parameter distributions \citep[e.g.][]{kleczkowski_parameter_2007, parry_bayesian_2014}. This could mean that fitting a single deterministic model may be challenging. The lack of data and potential losses from plant disease though \citep{savary_global_2019}, mean that robust decision making in the face of uncertainty is vital. The continued surveillance in the update steps of MPC could allow robustness to this type of parameter uncertainty: an important question we will address in Chapter~\ref{ch:protect_tanoak_control}. The continued surveillance could also incorporate improved knowledge of parameters as the simulation proceeds \citep{thompson_control_2018}.

\subsection{Practical implementation}

The feedback in MPC requires continued surveillance of the system to assess the state of the epidemic. Both open-loop and MPC are known as feed-forward controllers since control is optimised using predictions of the future dynamics. Accurate predictions can avoid continuous or very frequent surveys which may be expensive or logistically challenging. However, the repeated updates in the feedback loop of MPC improve these predictions and hence the performance of the control. Whilst each update improves control, the associated surveillance could be expensive, and so surveillance costs must be balanced with the improvement in disease management. This could be done by varying the update frequency or the intensity of surveillance, both of which we analyse in more detail in Chapter~\ref{ch:protect_tanoak_control}.

We have shown in this chapter that open-loop and MPC frameworks are able to transfer optimal control results to more realistic simulations and so to practical application, but the complexity of the resulting strategies does raise the issue of communicability of results. With complex feedback strategies between two models, one complex in structure and the other mathematically complex, the overall result is no longer simple to explain. The ultimate proof of performance though, is in the strategy testing technique using the simulation model. If potential strategies can be evaluated by stakeholders for real-world implementation using a complex model, as was the case for HPV \citep{choi_transmission_2010} and citrus diseases \citep{cunniffe_optimising_2015} for example, then the open-loop and MPC frameworks can simply be added as an alternative strategy for evaluation. Future research must therefore focus on improving the accuracy of simulation models, and analysing their reliability, so that simulations can be used to establish conclusively the benefit of these complex OCT based strategies.

\section{Conclusions}

OCT can be used to find effective control strategies for complex systems by applying OCT to an approximate model of the simulation. Results can then be lifted to the simulation for evaluation. In open-loop the optimised controls are used over the full simulation time, whereas with MPC a feedback loop updates the approximate model at regular intervals. At these update times the initial conditions of the approximate model are set to the current state of the simulation model, and control is re-optimised and lifted to the simulation. Feedback allows control to closely match individual simulation realisations, improving control over open-loop. MPC provides an effective framework for identifying optimal control strategies.
